import re
from pathlib import Path
from typing import Dict, Tuple, List

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

CASTRR_METADATA_PATTERN = \
    re.compile(r'^.*<age-range>: (?P<age>\d+).*<sex>: (?P<sex>\w+).*$',
               re.DOTALL | re.MULTILINE)


def load_mhrv_xls(
        path: str, sheet_names: list, df_meta: pd.DataFrame = None
) -> Dict[str, pd.DataFrame]:
    """
    Loads raw data from excel file containing HRV features generated by mhrv.
    @param path: Path to file.
    @param sheet_names: Names of excel sheets to load.
    @param df_meta: Extra metadata about each record.
    Should be a dataframe where the index is the record name.
    @return: A dict from sheet name to pandas dataframe. The summary
    statistics rows will be removed. Each dataframe will have a multiindex
    of (rec, win) which are are record name and window number.
    """

    dfs: Dict[str, pd.DataFrame] = pd.read_excel(
        path, header=0, index_col=0,
        sheet_name=list(sheet_names),
    )

    summary_rows = ('Mean', 'Median', 'SE')
    for name, df in dfs.items():
        # Remove the rows which contain summary statistics
        df = df.loc[~df.index.isin(summary_rows), :]

        # Convert dtypes
        df = df.astype(np.float32, copy=False)
        df = df.astype(dict(RR=np.int32, NN=np.int32), copy=False)

        # Impute NaN with mean
        df = df.fillna(value=df.mean(skipna=True))

        # Replace index with multi-index
        df.index = pd.MultiIndex.from_tuples(
            [i.split("_") for i in df.index],
            names=['rec', 'win']
        )

        if df_meta is not None:
            # Join, but only keep rows from df
            df = df.join(df_meta, how='left')

        dfs[name] = df

        print(f'Loaded {name}: {len(df)} samples, {len(df.columns)} features')

    return dfs


def load_castrr_metadata(db_dir: str) -> pd.DataFrame:
    """
    Parses metadata (age and sex) from records of the physionet CAST RR
    database (crisdb).
    The database is available here.
    https://physionet.org/content/crisdb/1.0.0/
    @param db_dir:
    @return: A DataFrame where index is record name, and columns are (AGE,
    SEX).
    """
    meta = {}

    db_dir = Path(db_dir)
    assert db_dir.is_dir()

    header_paths = db_dir.glob('**/*.hea')
    for header_path in header_paths:
        rec_name = header_path.stem
        with open(str(header_path), 'r') as f:
            m = CASTRR_METADATA_PATTERN.match(f.read())
            if not m:
                print(f'WARNING: header does not match expected format in '
                      f'file {header_path}')
                continue
            meta[rec_name] = m.groupdict()

    df_meta = pd.DataFrame(meta).transpose().sort_index(axis=0)
    df_meta.index.name = 'rec'
    df_meta.columns = [c.upper() for c in df_meta.columns]
    return df_meta


def create_ci_dataset(
        df_control: pd.DataFrame, df_treated: pd.DataFrame,
        psd_type: str = 'AR', outcome_mse=True, outcome_dfa=True,
        ignore_features=(), random_seed=None,
) -> pd.DataFrame:
    """
    Creates the dataset for this project as a single dataframe.
    @param df_control: DataFrame with control data.
    @param df_treated: DataFrame with post-treatment data.
    @param psd_type: Type of PSD estimate to take from dataset,
    which contains multiple estimates as e.g. "VLF_POWER_WELCH". The
    selected variables will be renamed to e.g. "VLF_POWER".
    @return: Single dataframe with consolidated PSD features and a treatment
    column 'T'.
    """
    psd_suffix = f'_{psd_type.upper()}'

    dfs = {'control': df_control, 'treated': df_treated}

    patient_ids = {}
    covariates, outcomes = [], []

    for name, df in dfs.items():
        # Compute the outcome.
        df, outcome_cols = create_outcome_columns(
            df, outcome_mse, outcome_dfa, prefix=''
        )

        # Treat PSD columns: Keep only the requested type,
        # remove the other type and rename the columns.
        df = consolidate_psd(df, psd_suffix)

        # Mark the columns with prefixes and reorder dataframe
        df, covariates, outcomes = mark_dataset(
            df, outcome_cols, ignore=ignore_features,
            covariates_prefix='X_', outcomes_prefix='Y_'
        )

        # Extract patient ids. The index is ('rec', 'win') where rec
        # is e.g. 'e001a' for control or 'e001b' for treated of patient 'e001'.
        # Take level 0 of index ('rec') and remove last char of each value.
        pid_set = patient_ids.setdefault(name, set())
        pid_set.update(i[:-1] for i in df.index.levels[0])

        dfs[name] = df

    # Keep only patients for which we have both a control and treated record
    patient_ids = patient_ids['control'].intersection(patient_ids['treated'])

    # Names for counterfactual outcome columns
    outcomes_cf = [f'{o}_CF' for o in outcomes]

    # Now create the covariates.
    # Note that we have a control and treated record for each subject,
    # since we started with an ECG recording before and after the drug was
    # administered.
    #
    # To create a causal inference dataset, each subject will be assigned
    # for either the control or treatment groups. For subjects assigned to
    # the control group, we take their data as is. For subjects assigned to
    # the treatment group, we take the pre-treatment HRV features as
    # covariates and the post-treatment computed outcomes as outcome variables.

    if random_seed is not None:
        np.random.seed(random_seed)

    ids_control = sorted(
        np.random.choice(list(patient_ids), len(patient_ids) // 2,
                         replace=False)
    )
    ids_treated = sorted(patient_ids.difference(ids_control))

    # Add back the 'a/b' at the end of the patient id, which we removed before
    ids_control_control = [f'{i}a' for i in ids_control]  # for control
    ids_control_treated = [f'{i}b' for i in ids_control]  # for cf outcome

    ids_treated_control = [f'{i}a' for i in ids_treated]  # for pre-treatment
    ids_treated_treated = [f'{i}b' for i in ids_treated]  # for post-treatment

    # For roughly half of the patients, we'll only use the control data as is.
    df_control = dfs['control'].loc[ids_control_control]

    # Add counterfactual outcome from their post-treatment records
    # df_control_cf = dfs['treated'].loc[ids_control_treated][outcomes]
    # df_control_cf.columns = outcomes_cf
    # df_control = pd.concat([df_control, df_control_cf], axis=1)

    # For the other half of the patients, we need to take their covariates
    # from the pre-treatment data and their outcome from the post-treatment
    # data.
    df_treated_outcomes = dfs['treated'].loc[ids_treated_treated][outcomes]
    df_treated_covariates =\
        dfs['control'].loc[ids_treated_control][covariates].reindex(
            df_treated_outcomes.index
        )
    df_treated = pd.concat([df_treated_covariates, df_treated_outcomes],
                           axis=1)

    # Add counterfactual outcome from the pre-treatment records
    # df_treated_cf = dfs['control'].loc[ids_treated_control][outcomes]
    # df_treated_cf.columns = outcomes_cf
    # df_treated = pd.concat([df_treated, df_treated_cf], axis=1)

    # Assign treatment variable
    df_control = df_control.assign(T=0)
    df_treated = df_treated.assign(T=1)

    df = df_control.append(df_treated)
    return df


def create_outcome_columns(df: pd.DataFrame, mse=True, dfa=True, prefix="Y_"):
    """
    Creates outcome columns based on Multiscale Entropy (MSE) and Detrended
    Fluctuation Analysis (DFA) features, and drops these columns from the
    dataset.
    @param df: A dataframe with features from mhrv.
    @param mse: Whether to create MSE outcome column and drop the MSE
    feature columns.
    @param dfa: Whether to create DFA outcome column and drop the DFA
    feature column.
    @return: A tuple (df, outcome_colums) where df is a new dataframe with the
    added columns and outcome_colums is a list containing their names.
    @param prefix: Prefix to prepend to new columns.
    """

    assert mse or dfa
    outcome_columns = []
    feature_prefixes = {}
    if mse:
        feature_prefixes['MSE'] = 'mse'
    if dfa:
        feature_prefixes['DFA'] = 'alpha'

    for outcome_name, feature_prefix in feature_prefixes.items():
        cols = [c for c in df.columns if c.lower().startswith(feature_prefix)]
        mean = df[cols].mean(axis=1)
        outcome_column = f'{prefix}{outcome_name}'
        df = df.assign(**{outcome_column: mean})
        df = df.drop(columns=cols)
        outcome_columns.append(outcome_column)

    return df, outcome_columns


def mark_dataset(
        df: pd.DataFrame,
        outcomes: List[str],
        ignore=(),
        covariates_prefix="X_",
        outcomes_prefix="Y_",
) -> Tuple[pd.DataFrame, List[str], List[str]]:
    """
    Marks dataset variables as covariates or outcome variables.
    (Assumes no treatment variable exists).
    @param df: DataFrame containing the dataset to split.
    @param outcomes: Names of columns with outcome variables.
    @param ignore: Covariate names to remove.
    @param covariates_prefix: Prefix to give to covariate variables in the
    output.
    @param outcomes_prefix: Prefix to give to outcome variables in the
    output.
    @return: Tuple (df, covariates, outcomes) where df is a DataFrame with
    marked covariates and outcomes in this order and marked
    according to the prefixes; covariates and outcomes are the column names
    after marking them and removing the ignored features.
    """

    # Remove ignored columns
    if ignore:
        df = df.drop(columns=ignore, inplace=False)

    df_Y = df[outcomes]
    outcomes_map = {o: f'{outcomes_prefix}{o}' for o in outcomes}
    df_Y = df_Y.rename(columns=outcomes_map, inplace=False)

    covariates = [c for c in df.columns if c not in outcomes]
    df_X = df[covariates]
    covariates_map = {c: f'{covariates_prefix}{c}' for c in covariates}
    df_X = df_X.rename(columns=covariates_map, inplace=False)

    # Reorder columns
    return (
        pd.concat([df_X, df_Y], axis=1),
        list(covariates_map.values()), list(outcomes_map.values())
    )


def consolidate_psd(df: pd.DataFrame, psd_suffix):
    """
    Keep only one type of PSD features.
    @param df: A dataframe from mhrv output.
    @param psd_suffix: Suffix of PSD features we wish to keep, e.g. "AR".
    @return: The dataframe with other PSD types removed, and the requested
    features renamed to not include the prefix.
    """
    # Discover PSD columns
    cols = df.columns
    psd_cols = set(
        map(lambda c: c.split(psd_suffix)[0],
            filter(lambda c: c.endswith(psd_suffix), cols))
    )

    # Discover PDS colums of other types
    other_psd_type_cols = filter(lambda c: any(
        [c.startswith(n) and not c.endswith(psd_suffix) for n in psd_cols]
    ), cols)

    df = df.drop(columns=other_psd_type_cols)
    df = df.rename(
        lambda c: c if not c.endswith(psd_suffix) else c.split(psd_suffix)[0],
        axis='columns'
    )
    return df


def split_dataset(
        df: pd.DataFrame,
        covariates_prefix="X_",
        outcomes_prefix="Y_",
        treatment='T',
        scale_covariates=False,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """

    @param df: DataFrame to split.
    @param covariates_prefix: Prefix of the covariate variables in the
    input.
    @param outcomes_prefix: Prefix of the outcome variables in the
    input.
    @param treatment: Name of treatment variable.
    @param scale_covariates: Whether to scale the covariates using a
    standard scaler.
    @return: Tuple (X, y, y) containing the covariates, outcomes and
    treatment respectively.
    """
    covariates = [c for c in df.columns if c.startswith(covariates_prefix)]
    outcomes = [c for c in df.columns if c.startswith(outcomes_prefix)]

    X = df[covariates].values
    y = df[outcomes].values
    t = df[treatment].values.reshape(-1)

    if y.shape[1] == 1:
        y = y.reshape(-1)

    if scale_covariates:
        X = StandardScaler().fit_transform(X)

    return X, y, t
